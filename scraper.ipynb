{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09cadbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf80ae0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_words = ['data', 'machine learning', 'ai', 'ml ', 'statist', 'artificial intelligence', 'python']\n",
    "keyword = 'data scientist'\n",
    "def get_job_ids(trigger_words, keyword, geoid=102890719, search_count=250, headers=None, internship=False):\n",
    "    \"\"\"\n",
    "    Get job IDs from LinkedIn based on trigger words and keyword.\n",
    "    # explain the inputs and outputs\n",
    "    :param trigger_words: List of words to search for in job titles or descriptions.\n",
    "    :param keyword: Keyword to search for in job titles or descriptions.\n",
    "    :param geoid: Geographical ID for the job search location. Default is 102890719 (Netherlands).\n",
    "    :param search_count: Number of job postings to fetch. Default is 250.\n",
    "    :param headers: Optional headers for the request. If None, default headers will be used. If False, no headers will be used.\n",
    "    :return: List of job IDs that match the trigger words and keyword.\n",
    "    \"\"\"\n",
    "    job_ids = []\n",
    "    keyword = keyword.replace(' ', '%2B')\n",
    "    # round search_count to the nearest multiple of 25\n",
    "    search_count = (search_count // 25) * 25\n",
    "    if search_count > 1000:\n",
    "        search_count = 1000\n",
    "        print(f\"Search count exceeds 1000, setting to 1000.\")\n",
    "    if search_count < 25:\n",
    "        search_count = 25\n",
    "        print(f\"Search count is less than 25, setting to 25.\")\n",
    "    try:\n",
    "        headers\n",
    "    except NameError:\n",
    "        headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',\n",
    "        'Accept': '*/*',\n",
    "        'Accept-Language': 'en-US,en;q=0.9',\n",
    "        'Accept-Encoding': 'gzip, deflate, br',\n",
    "        'Connection': 'keep-alive',\n",
    "        'Referer': f'https://www.linkedin.com/jobs/search/?keywords={keyword}&location=Nederland&geoId={geoid}&trk=homepage-basic_jobs-search-bar_search-submit&position=1&pageNum=0',\n",
    "        }\n",
    "\n",
    "    for start in range(0, search_count, 25):\n",
    "        URL = f\"https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?keywords={keyword}&location=Nederland&geoId={geoid}&start={start}\"\n",
    "        if headers == False:\n",
    "            response = requests.get(URL)\n",
    "        else:\n",
    "            response = requests.get(URL, headers=headers)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error: Unable to fetch data from LinkedIn. Status code: {response.status_code}\")\n",
    "            # leave the loop if the request fails\n",
    "            break\n",
    "        else:\n",
    "            print(\"Data fetched successfully!\")\n",
    "            data = response.text\n",
    "        soup = BeautifulSoup(data, 'html.parser')\n",
    "        job_listings = soup.find_all('a', class_='base-card__full-link absolute top-0 right-0 bottom-0 left-0 p-0 z-[2]')\n",
    "\n",
    "\n",
    "        for job in job_listings:\n",
    "            if any(word in job.text.strip().lower() for word in ['intern', 'afstudeeropdracht', 'stage']):\n",
    "                if internship == False:\n",
    "                    print(f\"--- Job ID {job.text.strip()} is an intern position.\")\n",
    "            elif any(word in job.text.strip().lower() for word in trigger_words):\n",
    "                if internship == True:\n",
    "                    print(f\"--- Job ID {job.text.strip()} is an intern position.\")\n",
    "                else:\n",
    "                    job_ids.append(('').join(job.get('href').split('/')[5:]).split('-')[-1].split('?')[0])\n",
    "                    print(f\"!!! Job ID {job.text.strip()} contains trigger words.\")\n",
    "            else:\n",
    "                print(f\"Job ID {job.text.strip()} does not contain trigger words.\")\n",
    "        print('')\n",
    "        sleep(random.randint(0, 2))\n",
    "\n",
    "    print(f\"Total job IDs found: {len(job_ids)}\")\n",
    "    return job_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7382ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data fetched successfully!\n",
      "!!! Job ID Machine Learning Engineer contains trigger words.\n",
      "!!! Job ID Data Scientist contains trigger words.\n",
      "!!! Job ID Machine Learning Engineer contains trigger words.\n",
      "!!! Job ID Junior Data Scientist contains trigger words.\n",
      "!!! Job ID Machine Learning Engineer contains trigger words.\n",
      "!!! Job ID Data Scientist contains trigger words.\n",
      "--- Job ID Machine Learning Engineer - Internship is an intern position.\n",
      "!!! Job ID Data Scientist contains trigger words.\n",
      "!!! Job ID Data Scientist contains trigger words.\n",
      "!!! Job ID Data Scientist contains trigger words.\n",
      "\n",
      "Data fetched successfully!\n",
      "!!! Job ID Data Scientist contains trigger words.\n",
      "!!! Job ID Data Scientist contains trigger words.\n",
      "--- Job ID Data Science Intern(Analytics) is an intern position.\n",
      "!!! Job ID Data Scientist AI contains trigger words.\n",
      "!!! Job ID Data Scientist contains trigger words.\n",
      "!!! Job ID Data Scientist AI contains trigger words.\n",
      "!!! Job ID Data Scientist contains trigger words.\n",
      "!!! Job ID Data Scientist AI contains trigger words.\n",
      "!!! Job ID Data Science Specialist contains trigger words.\n",
      "!!! Job ID ML Engineer contains trigger words.\n",
      "\n",
      "Data fetched successfully!\n",
      "!!! Job ID AI/ML Engineer contains trigger words.\n",
      "!!! Job ID Data Scientist contains trigger words.\n",
      "!!! Job ID Data Scientist contains trigger words.\n",
      "!!! Job ID Machine Learning Engineer contains trigger words.\n",
      "!!! Job ID DATA SCIENTIST contains trigger words.\n",
      "!!! Job ID Machine Learning Engineer contains trigger words.\n",
      "!!! Job ID Artificial Intelligence Engineer contains trigger words.\n",
      "!!! Job ID AI Engineer contains trigger words.\n",
      "!!! Job ID Senior Machine Learning Engineer contains trigger words.\n",
      "!!! Job ID Adviseur plantfysiologie/ Data scientist contains trigger words.\n",
      "\n",
      "Data fetched successfully!\n",
      "!!! Job ID AI Specialist contains trigger words.\n",
      "!!! Job ID Lead Machine Learning Engineer contains trigger words.\n",
      "--- Job ID Data Science Intern is an intern position.\n",
      "!!! Job ID Data Analist & Scientist contains trigger words.\n",
      "!!! Job ID Founding AI Engineer contains trigger words.\n",
      "!!! Job ID Machine Learning Engineer contains trigger words.\n",
      "!!! Job ID Senior Machine Learning Engineer contains trigger words.\n",
      "!!! Job ID Traineeship Python developer contains trigger words.\n",
      "!!! Job ID Data Scientist contains trigger words.\n",
      "--- Job ID Data Science Intern is an intern position.\n",
      "\n",
      "Data fetched successfully!\n",
      "!!! Job ID Data Scientist II - Smart Benefits Insights contains trigger words.\n",
      "!!! Job ID Data Scientist - GenAI contains trigger words.\n",
      "!!! Job ID Machine Learning Engineer contains trigger words.\n",
      "!!! Job ID Data Scientist Gen AI contains trigger words.\n",
      "!!! Job ID Data Scientist (Rotterdam/ Eindhoven) contains trigger words.\n",
      "!!! Job ID Machine Learning Engineer contains trigger words.\n",
      "!!! Job ID Data Engineer / Scientist contains trigger words.\n",
      "!!! Job ID AI and Image Processing Engineer contains trigger words.\n",
      "--- Job ID Data Science Intern is an intern position.\n",
      "!!! Job ID Head of Data Science contains trigger words.\n",
      "\n",
      "Data fetched successfully!\n",
      "!!! Job ID AI/Machine Learning Engineer contains trigger words.\n",
      "!!! Job ID Why this Generative AI Engineer position is like Star Wars. contains trigger words.\n",
      "!!! Job ID Data Scientist contains trigger words.\n",
      "Job ID Software Developer Cancer Genomics does not contain trigger words.\n",
      "!!! Job ID Data Scientist contains trigger words.\n",
      "!!! Job ID Python Developer - Urgent/Immediate start (perm) contains trigger words.\n",
      "!!! Job ID AI-Native Professional Engineer contains trigger words.\n",
      "!!! Job ID AI specialist contains trigger words.\n",
      "Job ID nieuwe collega (open sollicitatie) does not contain trigger words.\n",
      "!!! Job ID Python Developer contains trigger words.\n",
      "\n",
      "Data fetched successfully!\n",
      "!!! Job ID Data Scientist contains trigger words.\n",
      "Job ID MLOps Engineer does not contain trigger words.\n",
      "--- Job ID Intern, Discovery Data Science (Project: Applied ML for single-cell data analysis for product discovery) is an intern position.\n",
      "!!! Job ID Data Scientist AI/ML in Product Development (ENG) contains trigger words.\n",
      "!!! Job ID Python Developer contains trigger words.\n",
      "!!! Job ID Python Developer contains trigger words.\n",
      "!!! Job ID Data Science Expert contains trigger words.\n",
      "!!! Job ID Data Scientist contains trigger words.\n",
      "!!! Job ID Data Scientist contains trigger words.\n",
      "!!! Job ID AI Engineer (LangGraph, LLMs, Retrieval, Reasoning) contains trigger words.\n",
      "\n",
      "Data fetched successfully!\n",
      "!!! Job ID Machine Learning Engineer - NL contains trigger words.\n",
      "!!! Job ID Senior Data Scientist, Amsterdam contains trigger words.\n",
      "!!! Job ID Data Scientist (Fluent in Dutch) contains trigger words.\n",
      "!!! Job ID Freelance - Data scientist - Retail contains trigger words.\n",
      "!!! Job ID Data Scientist, Ede contains trigger words.\n",
      "!!! Job ID Data Scientist bij Damen contains trigger words.\n",
      "!!! Job ID Python Software Engineer - Insights contains trigger words.\n",
      "!!! Job ID Senior Data Scientist contains trigger words.\n",
      "!!! Job ID Machine Learning Engineer contains trigger words.\n",
      "!!! Job ID Econoom en/of Data Scientist contains trigger words.\n",
      "\n",
      "Data fetched successfully!\n",
      "!!! Job ID Lead Data Scientist contains trigger words.\n",
      "!!! Job ID Data Scientist contains trigger words.\n",
      "!!! Job ID Data Scientist AI/ML in Product Development (ENG) contains trigger words.\n",
      "!!! Job ID Data Science Expert contains trigger words.\n",
      "--- Job ID Research Engineering Intern is an intern position.\n",
      "!!! Job ID Senior Machine Learning Engineer - Applied AI contains trigger words.\n",
      "!!! Job ID Lead Machine Learning Engineer - GenAI contains trigger words.\n",
      "!!! Job ID Data Science Expert contains trigger words.\n",
      "!!! Job ID Python Developer contains trigger words.\n",
      "--- Job ID Internship Finance – Data Analysis and Technical Skills is an intern position.\n",
      "\n",
      "Data fetched successfully!\n",
      "!!! Job ID Data Engineer AI contains trigger words.\n",
      "!!! Job ID Senior Machine Learning Scientist contains trigger words.\n",
      "!!! Job ID Data Scientist in Roermond contains trigger words.\n",
      "!!! Job ID Python Developer contains trigger words.\n",
      "!!! Job ID Data Science Expert contains trigger words.\n",
      "Job ID Open sollicitatie does not contain trigger words.\n",
      "!!! Job ID Senior Data Scientist contains trigger words.\n",
      "!!! Job ID Senior Researcher– Machine Learning – Microsoft Research contains trigger words.\n",
      "!!! Job ID Junior Researcher on Generative AI Use and Computational Social Science contains trigger words.\n",
      "!!! Job ID Data Engineer AI contains trigger words.\n",
      "\n",
      "Total job IDs found: 88\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['4207969860',\n",
       " '4190285194',\n",
       " '4081414959',\n",
       " '4187507643',\n",
       " '4193157782',\n",
       " '4206694302',\n",
       " '4202522884',\n",
       " '4166385107',\n",
       " '4190510848',\n",
       " '4166729606',\n",
       " '4167579820',\n",
       " '4207968748',\n",
       " '4125832494',\n",
       " '4207964942',\n",
       " '4197872763',\n",
       " '4207966830',\n",
       " '4195237062',\n",
       " '4199325380',\n",
       " '4044337676',\n",
       " '4202496500',\n",
       " '4192808833',\n",
       " '4198857360',\n",
       " '4185793767',\n",
       " '4198539672',\n",
       " '3875010257',\n",
       " '4174430599',\n",
       " '4081419833',\n",
       " '4200815282',\n",
       " '4204519336',\n",
       " '4196603277',\n",
       " '4198080271',\n",
       " '4172657877',\n",
       " '4203216584',\n",
       " '4191894579',\n",
       " '4186710091',\n",
       " '4192057590',\n",
       " '4210012538',\n",
       " '4203778839',\n",
       " '4078850232',\n",
       " '4202876806',\n",
       " '4190265425',\n",
       " '4175549195',\n",
       " '4148666946',\n",
       " '4200169359',\n",
       " '4211407011',\n",
       " '4210910725',\n",
       " '4188318993',\n",
       " '4211905147',\n",
       " '4207774997',\n",
       " '4205806612',\n",
       " '4204358737',\n",
       " '4161434847',\n",
       " '4180254954',\n",
       " '4211799731',\n",
       " '4211734065',\n",
       " '4193718162',\n",
       " '4202839744',\n",
       " '4197901555',\n",
       " '4208667000',\n",
       " '4153880617',\n",
       " '4202328052',\n",
       " '4206208512',\n",
       " '4209786990',\n",
       " '4207625812',\n",
       " '4192872796',\n",
       " '4207599086',\n",
       " '4177832691',\n",
       " '4187969088',\n",
       " '4186539697',\n",
       " '4201260042',\n",
       " '4208690381',\n",
       " '4203140468',\n",
       " '4158263022',\n",
       " '4211732136',\n",
       " '4197901619',\n",
       " '4159221363',\n",
       " '4202559286',\n",
       " '4197906135',\n",
       " '4194277893',\n",
       " '4207967700',\n",
       " '4151249355',\n",
       " '4177832738',\n",
       " '4198825098',\n",
       " '4197598813',\n",
       " '4192747138',\n",
       " '4131768295',\n",
       " '4194406631',\n",
       " '4207970514']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_ids = get_job_ids(trigger_words, keyword, geoid=102890719, search_count=250, headers=None, internship=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e63069cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n",
      "Data fetched successfully!\n"
     ]
    }
   ],
   "source": [
    "data = {'job_title' : [], 'job_company': [], 'job_location': [], 'days_ago': [], 'company_description': [], 'job_description': []}\n",
    "error_count = 0\n",
    "for idx,job_id in enumerate(job_ids):\n",
    "    URL = f\"https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/{job_id}\"\n",
    "    response = requests.get(URL, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error: Unable to fetch data from LinkedIn. Status code: {response.status_code}\")\n",
    "        data['job_title'].append('')\n",
    "        data['job_company'].append('')\n",
    "        data['job_location'].append('')\n",
    "        data['days_ago'].append('')\n",
    "        data['company_description'].append('')\n",
    "        data['job_description'].append('')\n",
    "        error_count += 1\n",
    "        if error_count > 5:\n",
    "            print(\"Too many errors, stopping the script.\")\n",
    "            break\n",
    "        sleep(3)\n",
    "        continue\n",
    "    else:\n",
    "        error_count = 0\n",
    "        print(\"Data fetched successfully!\")\n",
    "        data2 = response.text\n",
    "    soup2 = BeautifulSoup(data2, 'html.parser')\n",
    "    soup2.find('div', class_= \"show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden\")\n",
    "    text = soup2.get_text(strip=True, separator=\"~~\")\n",
    "    data['job_title'].append(text.split('~~')[0])\n",
    "    data['job_company'].append(text.split('~~')[1])\n",
    "    data['job_location'].append(text.split('~~')[2])\n",
    "    data['days_ago'].append(text.split('~~')[3].split(' ')[0])\n",
    "    data['company_description'].append((' ').join(text.split('~~')[10:12]))\n",
    "    job_desc = (' ').join(text.split('~~')[13:-12])\n",
    "    #if job_desc[0:12] == 'Remove photo':\n",
    "    #    job_desc = job_desc.split(' ')[49:]\n",
    "    data['job_description'].append(job_desc)\n",
    "    if idx+1 % 10 == 0:\n",
    "        print(f\"Processed {idx+1} job postings.\")\n",
    "    sleep(random.randint(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1645904d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLeaning linkedin prefixes\n",
    "for idx,desc in enumerate(data['job_description']):\n",
    "    if desc[:10] == 'Sign in to':\n",
    "        data['job_description'][idx] = desc[1212:]\n",
    "    elif desc[:12] == 'Remove photo':\n",
    "        if desc[291:][:6] == 'Use AI':\n",
    "            data['job_description'][idx] = desc[1642:]\n",
    "        else:\n",
    "            data['job_description'][idx] = desc[291:]\n",
    "    else:\n",
    "        data['job_description'][idx] = desc\n",
    "       \n",
    "job_links = [f\"https://www.linkedin.com/jobs/search/?currentJobId={job_id}\" for job_id in job_ids]\n",
    "len(job_links)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "# Check for duplicates\n",
    "df = df.drop_duplicates(subset=['job_title', 'job_company', 'job_location', 'days_ago', 'company_description', 'job_description'], keep='first')\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df['job_link'] = job_links\n",
    "df.to_csv('linkedin_jobs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b08298",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('linkedin_jobs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2355f821",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# Step 1: Expanded keywords in Dutch and English\n",
    "section_keywords = [\n",
    "    # English\n",
    "    \"skills\", \"requirements\", \"responsibilities\", \"who you are\", \"who are you\",\n",
    "    \"qualifications\", \"desired profile\", \"your background\", \"what you bring\", \n",
    "    \"about the candidate\", \"candidate profile\", \n",
    "    \"nice to have\", \"we are looking for\", \"we're looking for\", \n",
    "    \"looking for someone who\", \"experience and skills\", \"python\", \"years of experience\", \"SQL\"\n",
    "\n",
    "    # Dutch\n",
    "    \"wat ga je doen\", \"wat je gaat doen\", \"functie-eisen\", \"wie zoeken wij\", \n",
    "    \"wat breng je mee\", \"vaardigheden\", \"wie ben jij\", \"jouw profiel\", \n",
    "    \"gewenst profiel\", \"eisen\", \"jij bent\", \"jij hebt\", \"jouw kwalificaties\", \n",
    "    \"over jou\", \"wat wij zoeken\", \"wie we zoeken\", \"je profiel\", \n",
    "    \"wij zoeken iemand die\", \"wij zijn op zoek naar\"\n",
    "]\n",
    "\n",
    "# Step 2: Compile patterns for efficient matching (case-insensitive)\n",
    "patterns = [re.compile(rf\"\\b{re.escape(token)}\\b\", re.IGNORECASE) for token in section_keywords]\n",
    "\n",
    "def extract_relevant_sections(job_posting_text, context_window=1):\n",
    "    # Step 3: Tokenize text into sentences\n",
    "    sentences = sent_tokenize(job_posting_text)\n",
    "\n",
    "    # Step 4: Find sentences that match the patterns\n",
    "    matches = []\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        if any(p.search(sentence) for p in patterns):\n",
    "            # Optionally, capture surrounding sentences for context\n",
    "            start = max(0, i - context_window)\n",
    "            end = min(len(sentences), i + context_window + 1)\n",
    "            block = \" \".join(sentences[start:end])\n",
    "            matches.append(block)\n",
    "    relevant_text = (' ').join(matches)\n",
    "\n",
    "    return relevant_text\n",
    "\n",
    "# Example usage\n",
    "jobs_relevant = []\n",
    "for jobs in df['job_description']:\n",
    "    relevant_text = extract_relevant_sections(jobs, context_window=2)\n",
    "    jobs_relevant.append(relevant_text)\n",
    "\n",
    "# find the years of experience in the relevant text\n",
    "years_of_experience = []\n",
    "for job in df['job_description']:\n",
    "    match = re.search(r\"(\\d+)\\s*[-]?\\s*(?:years?|jaar)\", job, re.IGNORECASE)\n",
    "    if match:\n",
    "        years_of_experience.append(int(match.group(1)))\n",
    "    else:\n",
    "        years_of_experience.append(None)\n",
    "\n",
    "# Check for several key skills: python, sql, machine learning, data analysis, statistics, matplotlib, pandas, numpy, scikit-learn, tensorflow, pytorch, keras, data visualization, data wrangling, big data, cloud computing, pyspark, hadoop, spark, tableau, power bi, data mining, data engineering, data modeling, data governance, data quality, data architecture, data strategy, data storytelling, data ethics, data privacy, data security, data compliance, data management, data integration, data transformation, data pipeline, data lake, data warehouse, data mart, data catalog, data lineage, data profiling, data cleansing, data enrichment, data visualization tools, business intelligence tools, machine learning algorithms, deep learning algorithms, natural language processing (NLP), computer vision, reinforcement learning, unsupervised learning, supervised learning, tableau, apache airflow, apache kafka, data science, data analytics, data mining techniques, data analysis techniques, data visualization techniques, data storytelling techniques, data ethics principles, data privacy regulations, data security best practices, data compliance standards, docker, kubernetes, data science tools, data analytics tools, data mining tools, data visualization software, business intelligence software, machine learning frameworks, deep learning frameworks, natural language processing, computer vision, power bi\n",
    "\n",
    "skills = [\n",
    "    'python', 'sql', 'machine learning', 'data analysis', 'statistics', 'matplotlib', 'pandas', 'numpy',\n",
    "    'scikit-learn', 'tensorflow', 'pytorch', 'keras', 'data visualization', 'data wrangling', \n",
    "    'big data', 'cloud computing', 'pyspark', 'hadoop', 'spark', 'tableau', 'power bi',\n",
    "    'data mining', 'data engineering', 'data modeling', 'data governance', \n",
    "    'data quality', 'data architecture', 'data strategy', \n",
    "    'data storytelling', 'data ethics', \n",
    "    'data privacy', 'data security',\n",
    "    'data compliance', 'data management',\n",
    "    'data integration', 'data transformation',\n",
    "    'data pipeline', 'data lake', 'data warehouse',\n",
    "    'data mart', 'data catalog', 'data lineage',\n",
    "    'data profiling', 'data cleansing',\n",
    "    'data enrichment', 'data visualization tools',\n",
    "    'business intelligence tools',\n",
    "    'machine learning algorithms',\n",
    "    'deep learning algorithms',\n",
    "    'natural language processing (NLP)',\n",
    "    'computer vision',\n",
    "    'reinforcement learning',\n",
    "    # Add more skills as needed\n",
    "]\n",
    "\n",
    "skills_found = []\n",
    "for job in df['job_description']:\n",
    "    found_skills = [skill for skill in skills if re.search(rf\"\\b{re.escape(skill)}\\b\", job, re.IGNORECASE)]\n",
    "    skills_found.append(found_skills)\n",
    "\n",
    "df['skills'] = skills_found\n",
    "df['years_of_experience'] = years_of_experience\n",
    "df['relevant_text'] = jobs_relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fee01cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
